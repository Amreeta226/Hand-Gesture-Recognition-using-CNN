{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD0NdmASh3-V"
      },
      "source": [
        "# Deep Learning-CNN based hand gesture recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvV6rx8qh3-c"
      },
      "source": [
        "This project involves building a 3D Convolutional Neural Network (CNN) to correctly recognize hand gestures by a user to control a smart TV.\n",
        "\n",
        "The objective of this projects is to build a hand gesture recognition model that can be hosted on a camera installed in a smart TV that can understand 5 gestures. Namely, leftwards hand movement to go to previous channel, rightward hand movement to go to next channel, upward hand movement to increase the volume, downward hand movement to decrease the volume and a palm gesture to pause playing the video."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from imageio import imread\n",
        "from skimage.transform import resize\n",
        "import datetime"
      ],
      "metadata": {
        "id": "tzI9if5JixrD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbYgWYO0h3-e"
      },
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)"
      ],
      "metadata": {
        "id": "Pl_xD-v6jSsE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp7mOHZ0h3-g"
      },
      "source": [
        "In this block, folder names for training and validation are read. We also set the `batch_size` here. We set the batch size in such a way that we are able to use the GPU in full capacity. We keep increasing the batch size until the machine throws an error."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_doc = np.random.permutation(open('/content/storage/Final_data/Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('/content/storage/Final_data/Project_data/val.csv').readlines())\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "dJSvL7FyuTtt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQYEfHOIh3-g"
      },
      "source": [
        "## Generator\n",
        "In the generator, we are going to preprocess the images as we have images of 2 different dimensions as well as create a batch of video frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TYpdnxijh3-h"
      },
      "outputs": [],
      "source": [
        "def generator(source_path, folder_list, batch_size):\n",
        "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    img_idx = [0,1,2,4,6,8,10,12,14,16,18,20,22,24,26,27,28,29]\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = int(len(t)/batch_size)\n",
        "        for batch in range(num_batches):\n",
        "            batch_data = np.zeros((batch_size,18,84,84,3))\n",
        "            batch_labels = np.zeros((batch_size,5))\n",
        "            for folder in range(batch_size):\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0])\n",
        "                for idx,item in enumerate(img_idx):\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    if image.shape[1] == 160:\n",
        "                        image = imresize(image[:,20:140,:],(84,84)).astype(np.float32)\n",
        "                    else:\n",
        "                        image = imresize(image,(84,84)).astype(np.float32)\n",
        "\n",
        "                    batch_data[folder,idx,:,:,0] = image[:,:,0] - 104\n",
        "                    batch_data[folder,idx,:,:,1] = image[:,:,1] - 117\n",
        "                    batch_data[folder,idx,:,:,2] = image[:,:,2] - 123\n",
        "\n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels\n",
        "\n",
        "        if (len(t)%batch_size) != 0:\n",
        "            batch_data = np.zeros((len(t)%batch_size,18,84,84,3))\n",
        "            batch_labels = np.zeros((len(t)%batch_size,5))\n",
        "            for folder in range(len(t)%batch_size):\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (num_batches*batch_size)].split(';')[0])\n",
        "                for idx,item in enumerate(img_idx):\n",
        "                    image = imread(source_path+'/'+ t[folder + (num_batches*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    if image.shape[1] == 160:\n",
        "                        image = imresize(image[:,20:140,:],(84,84)).astype(np.float32)\n",
        "                    else:\n",
        "                        image = imresize(image,(84,84)).astype(np.float32)\n",
        "\n",
        "                    batch_data[folder,idx,:,:,0] = image[:,:,0] - 104\n",
        "                    batch_data[folder,idx,:,:,1] = image[:,:,1] - 117\n",
        "                    batch_data[folder,idx,:,:,2] = image[:,:,2] - 123\n",
        "\n",
        "                batch_labels[folder, int(t[folder + (num_batches*batch_size)].strip().split(';')[2])] = 1\n",
        "\n",
        "            yield batch_data, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYIt4ZfBh3-h",
        "outputId": "efec15cb-0f90-47f7-8c0c-87eba59cfc0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# training sequences = 663\n",
            "# validation sequences = 100\n",
            "# epochs = 30\n"
          ]
        }
      ],
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = '/notebooks/storage/Final_data/Project_data/train'\n",
        "val_path = '/notebooks/storage/Final_data/Project_data/val'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('# training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "num_epochs = 30\n",
        "print ('# epochs =', num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dh7V-XTh3-i"
      },
      "source": [
        "## Model\n",
        "A model is created using different functionalities that Keras provides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EVI5C93Vh3-i"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GRU, Dropout, Flatten, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D  # Import from tensorflow.keras.layers\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
        "\n",
        "model.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
        "\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
        "\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='elu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0aCsOzsh3-j"
      },
      "source": [
        "Now compiling the model and looking at the summary to find out the number of parameters of the model. The number of parameters of the model is important since the model has to be light enough to be hosted on a webcam itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hubiTG6mh3-j",
        "outputId": "46395c8e-0b0a-4afe-eabd-93afdf693e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 18, 84, 84, 64)    5248      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 18, 84, 84, 64)    256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 18, 84, 84, 64)    0         \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3  (None, 9, 42, 84, 64)     0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 9, 42, 84, 128)    221312    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 9, 42, 84, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 9, 42, 84, 128)    0         \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPoolin  (None, 4, 21, 42, 128)    0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 4, 21, 42, 256)    884992    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 4, 21, 42, 256)    1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 4, 21, 42, 256)    0         \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPoolin  (None, 2, 10, 21, 256)    0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " conv3d_3 (Conv3D)           (None, 2, 10, 21, 256)    1769728   \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 2, 10, 21, 256)    1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 2, 10, 21, 256)    0         \n",
            "                                                                 \n",
            " max_pooling3d_3 (MaxPoolin  (None, 1, 5, 10, 256)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12800)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12800)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               6554112   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9440773 (36.01 MB)\n",
            "Trainable params: 9439365 (36.01 MB)\n",
            "Non-trainable params: 1408 (5.50 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "sgd = optimizers.SGD(learning_rate=0.001, momentum=0.7, nesterov=True)\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-tcl-X7h3-o"
      },
      "source": [
        "Creating the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dPVPYNbQh3-o"
      },
      "outputs": [],
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eo74aFMh3-p",
        "outputId": "cf87e1d9-fcc9-41ec-b1e5-bbea378b273e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        }
      ],
      "source": [
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001)\n",
        "callbacks_list = [checkpoint, LR]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BG2nz5Geh3-q"
      },
      "outputs": [],
      "source": [
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRIkhkhxh3-v"
      },
      "source": [
        "Fitting the model and saving checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import imageio\n",
        "\n",
        "def generator(source_path, folder_list, batch_size):\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = len(folder_list) // batch_size\n",
        "        for batch in range(num_batches):\n",
        "            batch_data = np.zeros((batch_size, 18, 84, 84, 3)) # Initialize batch data\n",
        "            batch_labels = np.zeros((batch_size, 5)) # Initialize batch labels\n",
        "            for folder in range(batch_size):\n",
        "                try:\n",
        "                    folder_path = os.path.join(source_path, t[folder + (batch * batch_size)].split(';')[0])\n",
        "                    imgs = os.listdir(folder_path)\n",
        "                    for idx, item in enumerate(imgs):\n",
        "                        image_path = os.path.join(folder_path, item)\n",
        "                        if os.path.isfile(image_path):\n",
        "                            image = imageio.imread(image_path).astype(np.float32)\n",
        "                            # Add the image data to batch_data\n",
        "                            # Modify this part according to your specific requirements\n",
        "                            # Assuming you're loading images and storing them in batch_data\n",
        "                            batch_data[folder, idx, :, :, 0] = image[:, :, 0] / 255\n",
        "                            batch_data[folder, idx, :, :, 1] = image[:, :, 1] / 255\n",
        "                            batch_data[folder, idx, :, :, 2] = image[:, :, 2] / 255\n",
        "                    batch_labels[folder, int(t[folder + (batch * batch_size)].strip().split(';')[2])] = 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading files from {folder_path}: {e}\")\n",
        "                    continue\n",
        "            yield batch_data, batch_labels\n"
      ],
      "metadata": {
        "id": "PdFFF6lVyFA3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBD6LYmrh3-x"
      },
      "source": [
        "## Model accuracy\n",
        "According to the epoch runs shown above, the model achieves a 'validation categorical accuracy' of 76% after 30 epochs. This can be considerably improved by running more epochs. Due to computational constraints, only 30 epoch runs have been selected for this analysis."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}